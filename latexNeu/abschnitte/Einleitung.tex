\section{Einleitung}

Augmented Reality (AR) ist eine Vermischung der realen Welt mit virtuellen Elementen. Es wird durch Anzeigegeräte, wie Handys, Tablets oder Augmented Reality Brillen präsentiert und bietet ein intuitives Benutzerinterface, um Objekte der realen Welt mit Informationen anzureichern. Eine AR-Umgebung bietet dem Nutzer eine erweiterte Wahrnehmung der realen Welt, indem sie diese anzeigt und gleichzeitig 3D-Objekte, 2D-Overlays oder Audioelemente  hinzufügt. 

Die Interaktion der virtuellen Elemente miteinander, mit dem Nutzer und der realen Umgebung ist ein Grundbestandteil von AR-Anwendungen.
Um die Interaktion mit der Umgebung zu ermöglichen, müssen Informationen über die Geometrie der Umgebung vorliegen. Es gibt somit ein grobes Verständnis davon, wie ein Mesh der Umgebung aussieht. 

Dieses geometrische Verständnis kann durch ein semantisches Verständnis der Umgebung erweitert werden. Letzteres ermöglicht komplexere Interaktionen zwischen digitalen und virtuellen Elementen. Semantische Informationen werden durch die Gegenstände erschlossen, die sich in der Umgebung befinden. 

%wie wird objekt erkennung gemacht
Eine Möglichkeit, um Objekte in der Umgebung zu erkennen, verwendet Markierungen der realen Welt. Dabei handelt es sich um statische Bilder, beispielsweise um ein Foto oder einen QR-Code. Die Markierungen werden von einer Kamera eingescannt. Der Marker ist einzigartig für jeden Gegenstand. So können die Objekte eindeutig voneinander unterschieden werden. Der Nachteil bei diesem Vorgehen ist ein hoher Arbeitsaufwand. Dieser entsteht durch die Notwendigkeit, jeden Gegenstand der realen Welt einzeln zu markieren.

Markierungen in der realen Welt können umgangen werden, indem der Nutzer per Geste auf Objekte der realen Welt weist, die vom System erkannt werden sollen. Für jedes dieser Objekte muss der Nutzer angeben, um welche Art von Gegenstand es sich handelt. Auf diese Weise kann die Applikation unterschiedliche Objekte unterscheiden. Auch hier ist der Arbeitsaufwand hoch. Dieser Nachteil ergibt sich aus der hohen Anzahl erforderlicher Gesten.

%also basically per hand. was ziemlich schlecht ist. % es bleibt nur übrig automatisch zu tracken
Aufgrund ihres hohen Arbeits- und Zeitaufwandes sind beide beschriebene Verfahren ungeeignet für den Zweck, Objekte in großen oder dynamischen Umgebungen zu erkennen. Nur eine vollautomatische Objekterkennung lässt sich gut skalieren. Mit dieser Methode können semantische Informationen einer reale Umgebung mit deutlich weniger Aufwand erfasst werden. So lassen sich komplexe Anwendungsgebiete für Augmented Reality erschließen.

%object detection funktoniert was bilder angeht.
Um eine automatisierte Objekterkennung zu erreichen, kann 'Object Detection' aus dem Bereich der Computer Vision verwendet werden.
'Object Detection' ist darauf ausgelegt, Objekte in RGB-Bildern zu erkennen.\citep{introToCNN}
%todo vergleich zu 3d interpretationen
%Die Objekterkennung mithilfe von 2D Abbildungen ist sehr performant.
%Und Besser als Versuche 3D Wolken zu interpretieren
%Diese Automatisierung wollen wir in dies
\subsection{Zielsetzung}

Thema dieser Arbeit ist die automatische Erkennung von Objekten in einer AR-Umgebung mithilfe von 'Object Detection'. 
Die AR-Brille 'Magic Leap One Lightwear' wird als Benutzerinterface und als Plattform verwendet.

Das Minimalziel besteht darin, Fotos der Umgebung zu analysieren und gefundene Objekte in einer 3D-Szene mit Labels zu versehen. 
Mithilfe der Kamera des AR-Gerätes werden Fotos von der Umgebung aufgenommen. Alle Fotos werden durch ein trainiertes neuronales Netzwerk nach Objekten durchsucht. Die neuronalen Netze geben für die gefundenen Fotos sowohl eine Klasse als auch eine Position auf dem Foto an. Die jeweiligen Positionen werden in einer digitalen Abbildung der Umgebung lokalisiert und mit Labels markiert.

Das erweitere Ziel besteht darin, ein zweites neuronales Netzwerk in die Objekterkennung einzubinden. Dieses kann trainiert werden, um spezifische Objekte zu erkennen. Auf diese Weise, sollen die semantischen Informationen erweitert werden, die von der Applikation erkannt werden können.

Als Maximalziel werden die Labels der erkannten Objekte als virtuelle Elemente mit der AR-Brille 'Magic Leap One' angezeigt.
%Mithilfe der Kameras der Hololens werden Fotos von der Umgebung aufgenommen. Diese Fotos werden, durch ein trainiertes Neuronales Netzwerk, nach Objekten durchsucht. 
%Die Positionen der Objekte werden in der digitalen Abbildung der Umgebung mit Labels markiert. Die Umgebung wird durch die Hololens erzeugt und in Unity mit den Labels versehen.
%
%\subsection*{Erweitertes Ziel}
%Die Object Detection wird durch ein speziell Trainiertes Neuronales Netzwerk erweitert um spezifischere Objekte zu erkennen.
%
%\subsection*{Maximalziel}
%Es wird ein Neuronales Netzwerk von Grund an erzeugt und trainiert um die Objekte zu detektieren und die Labels werden von der Hololens in Augmented Reality angezeigt.


%\subsection{Zitate}
%\cite{mlglossary} sagen hier steht ein Text. \\ %<-- Magic Leap (2020b) sais
%\citet{mlappsecurity} sagen hier steht ein Text. \\
%\citet*{mlappsecurity} sagen hier steht ein Text. \\
%"`Hier steht ein Text."' \citep{mlappsecurity} \\ %<-- this one
%Hier steht ein Text. \citep[Vgl.][]{mlappsecurity} \\
%Hier steht ein Text. \citep[][S. 200]{mlappsecurity} \\
%Hier steht ein Text. \citep*[][S. 200]{mlappsecurity} \\
%Hier steht ein Text. \citep{mlappsecurity,mlglossary,mlluminOS} \\ %<-- and this one is the same

